# Deep Learning Model -- SeqXGPT

Our model based on SeqXGPT, please refer to the [SeqXGPT](https://github.com/Jihuai-wpy/SeqXGPT/tree/main).

Our training checkpoints are saved on the [HuggingFace](https://huggingface.co/Roxanne-WANG/AI-Text-Detection).

## Datasets

Each dataset contains six files. Within each dataset folder, based on the source of AI-generated sentences in the document, they are organized into different files. You can refer to the requirements of different tasks in the paper to arrange and merge the files. Below are SeqXGPT-Bench and two important evaluation datasets. (This folder should be put under dataset/) The SeqXGPT-Bench is a sentence-level AI-generated text (AIGT) detection dataset used for the study of fine-grained AIGT detection.

We upload raw data and data with extracted features on the [HuggingFace](https://huggingface.co/datasets/Roxanne-WANG/AI-Text_Detection).

#### Raw Data Format

```python
{
    "text": "Media playback is unsupported on your device 21 June 2013 Last updated at 12:31 BST The Market Hall Cinema in Brynmawr used to be run by the local council but when it announced its funding would stop last month, work began to find a way to keep it going. Thanks to the efforts of a group of local volunteers, the cinema has been saved and reopened under a new community initiative. The group, called \"Brynmawr Foundation\", raised enough funds to take over the lease of the building and purchase new equipment. They plan to show a mix of classic and new films, as well as host events and live performances. The Market Hall Cinema has been an important part of the town's history since it first opened in 1894, and this new initiative ensures that it will continue to be a valuable resource for the community.", 
    "prompt_len": 254, 
    "label": "gpt3re"
}
```

​	**`text`**: The full document containing both human-written and AI-generated content.

​	**`prompt_len`**: An integer marks the boundary between the sentences generated by humans and those generated by AI. The first `prompt_len` characters of the input `text`, i.e., *text[:prompt\_len]*, are the sentences generated by humans, while the rest are generated by a particular language model.

​	**`label`**: The label for each sentence, and there are six types of labels in total: `gpt2`, `llama`, `gpt3re`, `human`.

#### Processed Data Format

```python
{
    "losses": [3.0821034908294678],
    "begin_idx_list": [1],
    "ll_tokens_list": [[0.0, 4.58919095993042, 4.58919095993042, ... , 3.2181057929992676]],
    "label_int": 3, 
    "label": "gpt3re",
    "text": "Media playback is unsupported on your device 21 June 2013 Last updated at 12:31 BST The Market Hall Cinema in Brynmawr used to be run by the local council but when it announced its funding would stop last month, work began to find a way to keep it going. Thanks to the efforts of a group of local volunteers, the cinema has been saved and reopened under a new community initiative. The group, called \"Brynmawr Foundation\", raised enough funds to take over the lease of the building and purchase new equipment. They plan to show a mix of classic and new films, as well as host events and live performances. The Market Hall Cinema has been an important part of the town's history since it first opened in 1894, and this new initiative ensures that it will continue to be a valuable resource for the community.", 
}
```

    **`losses`**: A list of log-likelihood loss values indicating how well the model predicts the text.

    **`begin_idx_list`**: A list marking the index where AI-generated content begins in the text.

    **`ll_tokens_list`**: A list of lists containing log-likelihood scores for each token in the text.

    **`label_int`**: An integer representing the categorical label of the text source.

    **`label`**: A string indicating the origin of the text, such as `gpt2`, `llama`, `gpt3re`, `human`.

    **`text`**: The full document containing both human-written and AI-generated content.


| label_int | label  | count |
|-----------|--------|-------|
| 0         | gpt2   | 6000  |
| 1         | llama  | 5904  |
| 2         | human  | 5997  |
| 3         | gpt3re | 5994  |


### Document-Level Detection Dataset

A dataset used to evaluate the performance of various methods in document-level AIGT detection.

**data format:**

```python
{
    "text": "in this paper we consider the possible existence of unstable axisymmetric modes in kerr space times , resulting from exponentially growing solutions of the teukolsky equation .  we describe a transformation that casts the radial equation that results upon separation of variables in the teukolsky equation , in the form of a schrdinger equation , and combine the properties of the solutions of this equations with some recent results on the asymptotic behaviour of spin weighted spheroidal harmonics to prove the existence of an infinite family of unstable modes .  thus we prove that the stationary region beyond a kerr black hole inner horizon is unstable under gravitational linear perturbations .  we also prove that kerr space - time with angular momentum larger than its square mass , which has a naked singularity , is unstable .", 
    "label": "human"
}
```

​	**`text`** refers to an entire document.

​	**`label`** is the label for the document, and there are six types of labels in total: `gpt2`, `llama`, `gpt3re`, `human`.

### OOD Sentence-Level Detection Dataset

A dataset used to evaluate the performance of various methods on OOD data.

**data format** is the same as the data format of [SeqXGPT-Bench](#seqxgpt-bench).

## Inference Server

We GPT2-xl (1.5B) to construct the original features of our SeqXGPT and the contrastive features for Sniffer.

You can launch the inference server through `backend_api.py`. The startup command is as follows:

```bash
# --model: [gpt2]
python backend_api.py --port 6006 --timeout 30000 --debug --model=gpt2 --gpu=0
```

## Feature Extraction

After successfully starting the related inference server, you can extract **the original features of SeqXGPT** using `gen_features.py`:

```bash
python ./dataset/gen_features.py --get_en_features --input_file input.jsonl --output_file output.jsonl
```

**It's worth noting that** you need to modify the inference server's URL in this file to the URL of the server you started.

You can extract **the contrastive features for Sniffer** using:

```bash
python ./dataset/gen_features.py --get_en_features --input_file input.jsonl --output_file output_1.jsonl
```

```bash
python ./dataset/gen_features.py --process_features --input_file output_1.jsonl --output_file output_2.jsonl
```

## Models

### SeqXGPT

We have provided the **complete code** for the model, dataloader, and train/test-related function under the `SeqXGPT` folder.

Before training and testing, please refer to the [Feature Extraction](#feature-extraction) section to extract relevant features, which will serve as the `--data_path`. The reference command is as follows:

```bash
# split train / test dataset and then train. You can adjust the train/test ratio using '--train_ratio'.
python ./Seq_train/train.py --gpu=0 --split_dataset

# train
python ./Seq_train/train.py --gpu=0

# test
python ./Seq_train/train.py --gpu=0 --do_test

# test document-level AIGT detection
python ./Seq_train/train.py --gpu=0 --do_test --test_content
```

In our modified version of SeqXGPT, we introduce three extra operations on the document-level wave (i.e., the sequence of log probabilities) to further refine feature extraction and enhance generalization:

I. Patch-based Averaging:
We divide the wave into small patches and compute the average within each patch. This operation acts as a smoothing mechanism that reduces local noise and variability. By aggregating local statistics, each patch more reliably represents the dominant trend in that segment of the wave, thereby making the subsequent feature extraction more robust.

II. 2D Convolution Processing:
Instead of relying solely on 1D convolution (or other sequential models), we apply 2D convolution on the wave. This approach allows the model to capture local patterns along two dimensions simultaneously—both across the temporal axis and across feature channels. The 2D convolution effectively extracts rich spatial correlations and inter-channel interactions, which enhances the model’s ability to discern subtle differences in the wave patterns.

III. Patch Shuffling:
After dividing the wave into patches, we shuffle the order of these patches. Shuffling serves as a data augmentation strategy that encourages the model to learn features that are invariant to the exact ordering of local segments. By reducing dependency on sequential order, the model becomes less prone to overfitting and gains improved generalization performance when faced with varied or perturbed input sequences.


### DetectGPT

We have provided the complete code under the `DetectGPT` folder to obtain the loss for the perturbed sentences (a total of 40) and the loss for the original sentences.

Specifically, if used for **sentence-level AIGT detection**, you **need to** process the documents in the original dataset into individual sentences. You can use the following code:

```python
import nltk
sent_separator = nltk.data.load('tokenizers/punkt/english.pickle')

# text is the document to be split into sentences
sents = sent_separator.tokenize(text)
```

### Sniffer

We refer to the [Sniffer GitHub](https://github.com/OpenLMLab/Sniffer) and modify the original Sniffer to obtain the sentence-level Sniffer. For the complete code, see the `Sniffer` folder.

### Sent-RoBERTa

We implement sentence-level AIGT detection with RoBERTa based on the sentence classification task. The complete model, dataloader, and training codes can be found in the `Sent-RoBERTa` folder. It's important to **note that**, before inputting, you also need to process the documents in the original dataset into individual sentences.

### Seq-RoBERTa

We implement sentence-level AIGT detection with RoBERTa based on the sequence labeling task. The complete model, dataloader, and training codes can be found in the `Seq-RoBERTa` folder.

## Requirements

```bash
cd SeqXGPT
```

```bash
# create a new virtual environment, conda in this case
conda create -n seqx python=3.11
conda activate seqx
```
```bash
pip install -r requirements.txt
python utils/nltk_download.py
```

```bash
mkdir dataset/SeqXGPT_output # then put every training data (.jsonl files) you want to use here

python SeqXGPT/train.py --split_dataset --data_path dataset/SeqXGPT_output --train_path dataset/SeqXGPT_output/en_gpt2_tr.jsonl --test_path dataset/SeqXGPT_output/en_gpt2_te.jsonl --gpu=0
```

## License

This repository is released under the Apache License 2.0, following the same licensing as the original SeqXGPT project.


